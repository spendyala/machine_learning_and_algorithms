{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules of thumb\n",
    "\n",
    "Max Processes == 10s\n",
    "\n",
    "Max Threads == 100s\n",
    "\n",
    "Async methods == 1000s\n",
    "\n",
    "**You can't create infinite numbers of threads and processes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preferred technique -- use concurrent.futures for \"pooling\"\n",
    "\n",
    "\n",
    "[See the official docs](https://docs.python.org/3/library/concurrent.futures.html)\n",
    "\n",
    "### Executor\n",
    "\n",
    "An object which executes code for you, asynchronously\n",
    "\n",
    "### Future\n",
    "\n",
    "The status of an execution, it's return value, it's exception if there is one, etc.  Similar to a promise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def my_function(n):\n",
    "    return f\"This string has {n} in it\"\n",
    "\n",
    "# The with statement will ensure the executor is cleaned up when we are done\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    my_future = executor.submit(my_function, 123)\n",
    "    print(my_future)\n",
    "    print(my_future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use processes instead of threads\n",
    "\n",
    "# The with statement will ensure the executor is cleaned up when we are done\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor:\n",
    "    my_future = executor.submit(my_function, 123)\n",
    "    print(my_future)\n",
    "    print(my_future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling exceptions\n",
    "def my_function(n):\n",
    "    raise ValueError()\n",
    "    \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    my_future = executor.submit(my_function, 123)\n",
    "    print(my_future)\n",
    "    # print(my_future.result())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executor execution methods\n",
    "\n",
    "```python\n",
    "my_executor = ...\n",
    "\n",
    "my_future = my_executor.submit( my_function, arg, arg, arg, ...)\n",
    "\n",
    "my_generator = my_executor.map( my_function, iterable_args )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def my_function(n):\n",
    "    time.sleep(random.random()*n)    \n",
    "    if n >= 10:\n",
    "        raise ValueError()\n",
    "    return f\"This string has {n} in it\"\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as my_executor:\n",
    "    my_data = [ 1, 5, 10 ]\n",
    "    result = my_executor.map(my_function, my_data)\n",
    "    \n",
    "    # NOTE: my_future isn't a future!  It's a generator\n",
    "    print(result)\n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The with statement will ensure the executor is cleaned up when we are done\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as my_executor:\n",
    "    my_data = [ 1, 5, 10 ]\n",
    "    results = my_executor.map(my_function, my_data)\n",
    "    \n",
    "    for x in results:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A useful pattern: map()\n",
    "\n",
    "1.  Use the global map() method\n",
    "2.  Switch from map() to executor.map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from http://rasmusrasmussen.com/rtweets/\n",
    "some_tweets = [\n",
    "    'My big mug is a loaded gun, and I want to wake up. I care about ingenious alcohol, bro. #midnightrant #randomtweet',\n",
    "    'My cat is getting old, and I want to get a yo-yo. I care about hot drinks, apparently. #fishbite #randomtweet',\n",
    "    'My groove is over the top, and I want to level up. Historically stoic robots, until tomorrow. #someeats #randomtweet'\n",
    "]\n",
    "\n",
    "def remove_vowels(s):\n",
    "    vowels = ('a', 'e', 'i', 'o', 'u')\n",
    "    return ''.join([l for l in s if l not in vowels])\n",
    "\n",
    "\n",
    "for result in map(remove_vowels,some_tweets):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as my_executor:\n",
    "    for result in my_executor.map(remove_vowels,some_tweets):\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower level, and older api: multiprocessing\n",
    "\n",
    "### Pools of processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import random\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def do_something(n):\n",
    "    'I compute and block'\n",
    "    time.sleep(2)\n",
    "    return n+1\n",
    "    \n",
    "    \n",
    "pool = Pool(2)\n",
    "with pool:\n",
    "    result = pool.apply(do_something, (1,))\n",
    "    print(result)\n",
    "    result = pool.apply(do_something, (2,))\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pool = Pool(2)\n",
    "with pool:\n",
    "    # result1 is an multiprocessing.pool.AsyncResult object\n",
    "    result1 = pool.apply_async(do_something, (1,))\n",
    "    print(result1.ready())\n",
    "    \n",
    "    result2 = pool.apply_async(do_something, (2,))\n",
    "    print(result2.ready())\n",
    "    \n",
    "    print(result1.get(timeout=10))\n",
    "    print(result2.get(timeout=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pools of threads (same api, more or less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "def do_something(n):\n",
    "    'I compute and block'\n",
    "    time.sleep(2)\n",
    "    return n+1\n",
    "    \n",
    "    \n",
    "pool = Pool(2)\n",
    "with pool:\n",
    "    result = pool.apply(do_something, (1,))\n",
    "    print(result)\n",
    "    result = pool.apply(do_something, (2,))\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn\n",
    "\n",
    "Use a thread pool to fetch the contents of an array of websites.  Use any technique you'd like from what you have learned so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def read_a_website(url_string):\n",
    "    'Use this function to get your website contents'\n",
    "    with urllib.request.urlopen(url_string) as response:\n",
    "        return response.read()\n",
    "    \n",
    "def print_website_html(html):\n",
    "    print(html[:100])\n",
    "    \n",
    "websites_to_fetch = [\n",
    "    'https://google.com',\n",
    "    'https://proofpoint.com'\n",
    "    # add some more\n",
    "]\n",
    "\n",
    "# Fetch the websites using a thread executor, then a process executor\n",
    "# print the html from each website\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def read_a_website(url_string):\n",
    "    'Use this function to get your website contents'\n",
    "    with urllib.request.urlopen(url_string) as response:\n",
    "        return response.read()\n",
    "    \n",
    "def print_website_html(html):\n",
    "    print(html[:100])\n",
    "    \n",
    "websites_to_fetch = [\n",
    "    'https://google.com',\n",
    "    'https://proofpoint.com'\n",
    "    # add some more\n",
    "]\n",
    "\n",
    "# Fetch the websites using a thread pool\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as my_executor:\n",
    "    results = my_executor.map(read_a_website,websites_to_fetch)\n",
    "    for html in results:\n",
    "        print_website_html(html)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
