{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Basics\n",
    "===================================\n",
    "\n",
    "In our overview we demonstrated how we could use pandas as a tool to help us to better understand the data that we are \n",
    "working with.  For me this is the biggest benefit that Pandas provides for use as Data Scientist, a tool to quickly\n",
    "explore our dataset and through exploration to better understand the data.  \n",
    "\n",
    "Now, I will start by saying that Pandas is not a silver bullet (as with almost all technologies).  Pandas, by itself, is used\n",
    "by loading all the data into memory, which means on larger datasets Pandas starts to fail with OOM errors and incredible\n",
    "long execution times.  However, if you can work with just a subset of the larger dataset it can still give you some very powerful\n",
    "insight into your data.  \n",
    "\n",
    "For this notebook I am going to focus more on having you guys learn through practice then by giving you concrete examples, to\n",
    "that end I hope that you can follow along and gain a greater appreciation for pandas and the power that it provides.  \n",
    "\n",
    "To really understand and appreciate pandas we are going to need to use it with a dataset. For this notebook we are going to \n",
    "use the [City of Austin - Traffic Count Study](https://catalog.data.gov/dataset/traffic-count-study-area/resource/820bc731-bc7c-4598-a08d-8430ad141c60).\n",
    "\n",
    "This dataset contains the following details.  \n",
    "\n",
    "  * Location (`24 HOUR VOLUME COUNT LOCATIONS`)\n",
    "  * Northbound Total (`NB TOTAL`)\n",
    "  * Southbound Total (`SB TOTAL`) \n",
    "  * Eastbound Total (`EB TOTAL`)\n",
    "  * Westbound Total (`WB TOTOAL`)\n",
    "  * Total Volumen (`TOTAL VOLUME`)\n",
    "  * Measurement Date (`DATE`)\n",
    "    \n",
    "To start, we need to first import our needed modules and download the dataset we are going to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from ml_course.util.downloader import download_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading url https://data.austintexas.gov/api/views/cqdh-farx/rows.csv?accessType=DOWNLOAD to file /home/jovyan/project/ml_course/util/../../.data/austin.csv\n",
      "######\n",
      "File downloaded to /home/jovyan/project/ml_course/util/../../.data/austin.csv\n",
      "24 HOUR VOLUME COUNT LOCATIONS,NB TOTAL,SB TOTAL,EB TOTAL, WB TOTOAL,TOTAL VOLUME,DATE\n",
      "\"10th St East, 1000 blk - West of Waller St\",,,101,115,216,09/27/2005 12:00:00 AM\n",
      "\"10th St East, 1200 blk - West of Navasota St\",,,103,55,158,09/27/2005 12:00:00 AM\n",
      "\"10th St East, 600 blk - East of Red River St\",,,n/a,2240,2240,02/26/2009 12:00:00 AM\n",
      "\"10th St East, 700 blk - West of IH35 WSR                     1-way WB\",,,n/a,1599,1599,07/06/2005 12:00:00 AM\n"
     ]
    }
   ],
   "source": [
    "url = 'https://data.austintexas.gov/api/views/cqdh-farx/rows.csv?accessType=DOWNLOAD'\n",
    "save_name = 'austin.csv'\n",
    "austin_filename = download_data(url, save_name)\n",
    "\n",
    "!head -n 5 /home/jovyan/project/ml_course/util/../../.data/austin.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "While pandas does have a lot of functionality, there are really just two main building blocks that most everything\n",
    "else is built upon.  We are going to start out discussion focused on these two building blocks, how they interact\n",
    "and common ways to work with them.  \n",
    "\n",
    "The two main building blocks are the __DataFrame__ and __Series__ types.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "So, what is a dataframe?  To put it in simple terms, `a dataframe is like a relational database table`.  This is\n",
    "by far the easist way to see it from a Software Engineer's perspective.  The more formal answer comes from the\n",
    "original source that a dataframe was modeled from, which is a data frame in the __R__ programming language.  \n",
    "\n",
    "> A data.frame object in R has similar dimensional properties to a matrix, but it may contain categorical data\n",
    "as well as numeric. Each column in the data.frame is a vector containing the variable value for a given data instance,\n",
    "with each row corresponding to that instance.  \n",
    "\n",
    "Now a Pandas DataFrame consists of three main parts, these are:\n",
    "\n",
    "- The data\n",
    "- The index (label)\n",
    "- The columns (label)\n",
    "\n",
    "Now, some of you may be asking what is the difference between a 2 dimensional numpy array and a pandas DataFrame?  There are a couple\n",
    "of key things.  \n",
    "\n",
    "1. Two-dimensional numpy arrays must all be the same type but pandas columns can be different types\n",
    "2. Rows and Columns can be queried using custom string labels, not just offset indexes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Dataframe\n",
    "\n",
    "So let's start by creating our first dataframe and seeing what it provides for us.  There are several ways that we can\n",
    "create a dataframe, but for this notebook we are only going to focus on one version for simplicity. \n",
    "\n",
    "**NOTE:** For more details please look at the [pandas.DataFrame documentation here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>pandas@gmail.com</td>\n",
       "      <td>1</td>\n",
       "      <td>Frank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>asure@yahoo.com</td>\n",
       "      <td>2</td>\n",
       "      <td>Ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>old@aol.com</td>\n",
       "      <td>3</td>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>movingto@outlook.com</td>\n",
       "      <td>4</td>\n",
       "      <td>Jack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>longtimeago@oldrepublic.com</td>\n",
       "      <td>5</td>\n",
       "      <td>Luke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         email  id    name\n",
       "A             pandas@gmail.com   1   Frank\n",
       "B              asure@yahoo.com   2    Ryan\n",
       "C                  old@aol.com   3  George\n",
       "D         movingto@outlook.com   4    Jack\n",
       "E  longtimeago@oldrepublic.com   5    Luke"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "email    object\n",
       "id        int64\n",
       "name     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "    {'id': 1, 'name': 'Frank', 'email': 'pandas@gmail.com'},\n",
    "    {'id': 2, 'name': 'Ryan', 'email': 'asure@yahoo.com'},\n",
    "    {'id': 3, 'name': 'George', 'email': 'old@aol.com'},\n",
    "    {'id': 4, 'name': 'Jack', 'email': 'movingto@outlook.com'},\n",
    "    {'id': 5, 'name': 'Luke', 'email': 'longtimeago@oldrepublic.com'}\n",
    "], index=['A', 'B', 'C', 'D', 'E'])\n",
    "display(df)\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output above, there are a few things that we can immediately see.  \n",
    "\n",
    "1. The output looks like a table with two axes. \n",
    "2. Our axis values have string labels, not just numeric offsets\n",
    "  - Rows: A, B, C, D, E\n",
    "  - Columns: email, id, name\n",
    "3. Our dataframe consists of multiple types:\n",
    "  - object: email, name\n",
    "  - int64: id\n",
    "\n",
    "From the datatypes describe above, we see that there is an `int64`.  This datatype is part of the numpy dtype.\n",
    "Pandas is built on numpy and as such uses numpy dtypes for numeric columns.  The other type `object` is a little\n",
    "bit different.  As we mentioned above, a dataframe can store not just numeric data, but also categorical data in\n",
    "the form of strings.  Since strings don't have a numeric representation, they fall into the numpy catchall of\n",
    "`object`.  \n",
    "\n",
    "What is really interesting about the dtypes is that we didn't explicitly specify the type in the dataframe creation,\n",
    "rather the dataframe took the time to __guess__ what the correct datatype should be.  Later on we will go over how\n",
    "to fix the type when it guesses incorrectly but for now we can work with the types that have been supplied.  \n",
    "\n",
    "Dataframes also have some very handy functions that we can use on them to view the data, some of these methods are:\n",
    "\n",
    "- `head(n)` - Displays the first `n` rows from the dataframe\n",
    "- `tail(n)` - Like head, but displays the last `n` rows instead\n",
    "- `info(n)` - Overview of the dataframe including dtypes, shape and other info\n",
    "\n",
    "Let's practice with these methods on the austin dataset.  Since we have not yet created a dataframe from that\n",
    "dataset, we will first load the csv into a dataframe before running our first exercise.  \n",
    "\n",
    "**NOTE:** While we aren't really covering it here, pandas does provide a lot of functions for working with other\n",
    "data sources including: `excel`, `json`, `html` and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I will use df for most of the time a dataframe is created as a simple shorthand\n",
    "df = pd.read_csv(austin_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24 HOUR VOLUME COUNT LOCATIONS</th>\n",
       "      <th>NB TOTAL</th>\n",
       "      <th>SB TOTAL</th>\n",
       "      <th>EB TOTAL</th>\n",
       "      <th>WB TOTOAL</th>\n",
       "      <th>TOTAL VOLUME</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10th St East, 1000 blk - West of Waller St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>216</td>\n",
       "      <td>09/27/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10th St East, 1200 blk - West of Navasota St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>158</td>\n",
       "      <td>09/27/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10th St East, 600 blk - East of Red River St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2240</td>\n",
       "      <td>02/26/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10th St East, 700 blk - West of IH35 WSR      ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1599</td>\n",
       "      <td>07/06/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10th St West, 1000 blk - West of N. Lamar Blvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>373.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>661</td>\n",
       "      <td>01/24/2001 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10th St West, 1300 blk - West of Lorrain St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>697</td>\n",
       "      <td>06/05/2007 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10th St West, 600 blk - West of Nueces St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>01/11/2001 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10th St West, 800 blk - West of West Ave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2163.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>3088</td>\n",
       "      <td>01/30/2003 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10th St West, 900 blk - East of N. Lamar Blvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>3194</td>\n",
       "      <td>01/30/2003 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11th St East, 1100 blk - East of Waller St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4185.0</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>7973</td>\n",
       "      <td>06/26/2006 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11th St East, 600 blk - East of Red River St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6544.0</td>\n",
       "      <td>5387.0</td>\n",
       "      <td>11931</td>\n",
       "      <td>03/24/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11th St West, 200 blk - East of Lavaca St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3568.0</td>\n",
       "      <td>5416.0</td>\n",
       "      <td>8984</td>\n",
       "      <td>07/19/2011 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12th St East, 1300 blk - East of San Bernard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3644.0</td>\n",
       "      <td>4813.0</td>\n",
       "      <td>8457</td>\n",
       "      <td>06/23/2014 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12th St East, 1300 blk - West of Angelina St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3701.0</td>\n",
       "      <td>4395.0</td>\n",
       "      <td>8096</td>\n",
       "      <td>10/27/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12th St East, 1700 blk - East of Leona St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3393.0</td>\n",
       "      <td>4153.0</td>\n",
       "      <td>7546</td>\n",
       "      <td>10/27/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12th St East, 400 blk - West of Red River St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4016</td>\n",
       "      <td>02/28/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12th St East, 4500 blk - West of  Springdale Rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2609.0</td>\n",
       "      <td>2709.0</td>\n",
       "      <td>5318</td>\n",
       "      <td>03/22/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12th St East, 600 blk - East of Red River St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3658.0</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>6732</td>\n",
       "      <td>03/04/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12th St West, 1000 blk - West of N. Lamar Blvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3335.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>6040</td>\n",
       "      <td>02/26/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12th St West, 1000 blk - West of N. Lamar Blvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>7023</td>\n",
       "      <td>01/24/2001 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12th St West, 1300 blk - East of Lorrain St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>4755.0</td>\n",
       "      <td>7672</td>\n",
       "      <td>04/28/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12th St West, 1300 blk - East of Lorrain St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>4181</td>\n",
       "      <td>09/10/2001 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12th St West, 1400 Blk - West of Shelly Ave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>2071.0</td>\n",
       "      <td>3952</td>\n",
       "      <td>09/10/2001 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13th St East, 3100 Blk - West of Airport Blvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>492</td>\n",
       "      <td>09/13/2007 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13th St West, 200 Blk - East of Lavaca St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>06/08/2006 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13th St West, 300 Blk - West of Lavaca St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>574.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>574</td>\n",
       "      <td>06/08/2006 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14 1/2 St East, 3100 blk - West of Airport Blvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>550</td>\n",
       "      <td>09/13/2007 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14th St East, 2000 Blk - West of Alamo St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>376</td>\n",
       "      <td>02/27/2007 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15th St East, 400 blk - West of Red River St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15032.0</td>\n",
       "      <td>4309.0</td>\n",
       "      <td>19341</td>\n",
       "      <td>02/28/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15th St East, 600 blk - East of Red River St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14443.0</td>\n",
       "      <td>13807.0</td>\n",
       "      <td>28250</td>\n",
       "      <td>01/31/2011 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>Yandall Dr, 2600 blk - West of Buster Crabbe Dr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>788</td>\n",
       "      <td>02/26/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>Yandall Dr, 2800 blk - East of Arbor Downs Rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>515</td>\n",
       "      <td>02/17/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>Yandall Dr, 2800 blk - East of Arbor Downs Rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>428.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>804</td>\n",
       "      <td>02/26/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>Yates Ave, 6700 blk - North of Redlands St</td>\n",
       "      <td>441</td>\n",
       "      <td>463.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>904</td>\n",
       "      <td>10/20/2003 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>Yates Ave, 6700 blk - North of Redlands St</td>\n",
       "      <td>393</td>\n",
       "      <td>492.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>885</td>\n",
       "      <td>01/28/2003 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>Yates Ave, 6800 blk - South of Justin Ln</td>\n",
       "      <td>483</td>\n",
       "      <td>459.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>942</td>\n",
       "      <td>01/28/2003 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>Yates Ave, 7000 blk - North of Cullen Ave</td>\n",
       "      <td>377</td>\n",
       "      <td>424.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>801</td>\n",
       "      <td>06/16/2008 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>Yates Ave, 7100 blk - South of Piedmont Ave</td>\n",
       "      <td>426</td>\n",
       "      <td>451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>877</td>\n",
       "      <td>11/14/2007 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>Yates Ave, 7200 blk - South of Madison Ave</td>\n",
       "      <td>434</td>\n",
       "      <td>414.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>848</td>\n",
       "      <td>06/16/2008 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>Yates Ave, 7400 blk - South of Richcreek Rd</td>\n",
       "      <td>471</td>\n",
       "      <td>467.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>938</td>\n",
       "      <td>11/14/2007 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>Yaupon Dr, 6200 blk - South of Senicio Dr</td>\n",
       "      <td>1371</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2781</td>\n",
       "      <td>02/02/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>Yaupon Dr, 6200 blk - South of Senicio Dr</td>\n",
       "      <td>1426</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2871</td>\n",
       "      <td>06/14/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>Yaupon Dr, 6400 blk - South of Copper Lily Cove</td>\n",
       "      <td>1125</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2245</td>\n",
       "      <td>06/14/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>Yaupon Dr, 6700 blk - South of Bully Hill Cove</td>\n",
       "      <td>1071</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2146</td>\n",
       "      <td>06/14/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>Yaupon Dr, 7100 blk - North of Croton Dr</td>\n",
       "      <td>1084</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2174</td>\n",
       "      <td>06/14/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>Yaupon Dr, 7300 blk - North of Swan Valley Lane</td>\n",
       "      <td>1275</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2551</td>\n",
       "      <td>02/02/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>Yaupon Dr, 7300 blk - North of Swan Valley Lane</td>\n",
       "      <td>1162</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2346</td>\n",
       "      <td>06/14/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>Yaupon Dr, 7400 blk - North of Fabion Dr</td>\n",
       "      <td>1266</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2554</td>\n",
       "      <td>06/14/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>Yaupon Dr, 7600 blk - North of Fireoak</td>\n",
       "      <td>1705</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3085</td>\n",
       "      <td>04/01/2014 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>Yaupon Dr, 7600 blk - North of Fireoak Dr</td>\n",
       "      <td>1333</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2380</td>\n",
       "      <td>10/20/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>Yaupon Dr, 7600 blk - North of Fireoak Dr</td>\n",
       "      <td>982</td>\n",
       "      <td>903.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1885</td>\n",
       "      <td>06/14/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>Yaupon Dr, 7600 blk - South of Blue Lily Dr.</td>\n",
       "      <td>1819</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3117</td>\n",
       "      <td>10/20/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>Yaupon Dr, 7700 blk - South of Cassia Dr</td>\n",
       "      <td>1244</td>\n",
       "      <td>935.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2179</td>\n",
       "      <td>02/02/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>Yaupon Dr, 7700 blk - South of Cassia Dr</td>\n",
       "      <td>972</td>\n",
       "      <td>911.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1883</td>\n",
       "      <td>06/14/2004 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>York Bridge Circle, 5700 blk - East of Manipar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>327</td>\n",
       "      <td>04/17/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>York Bridge Circle, 6400 blk - East of Manipar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>406</td>\n",
       "      <td>02/28/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>Zachary Scott, (@ Airport Blvd) - East of Airp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>2661</td>\n",
       "      <td>02/22/2010 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>Zachary Scott, 2000 blk - South of Scales St</td>\n",
       "      <td>790</td>\n",
       "      <td>603.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1393</td>\n",
       "      <td>02/13/2012 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>Zennia, 600 blk - East of Huisache Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>444</td>\n",
       "      <td>09/11/2012 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>Zimmerman Ln, 11300 blk - East of RM 620, E. o...</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>08/29/2005 12:00:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3341 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         24 HOUR VOLUME COUNT LOCATIONS NB TOTAL  SB TOTAL  \\\n",
       "0            10th St East, 1000 blk - West of Waller St      NaN       NaN   \n",
       "1          10th St East, 1200 blk - West of Navasota St      NaN       NaN   \n",
       "2          10th St East, 600 blk - East of Red River St      NaN       NaN   \n",
       "3     10th St East, 700 blk - West of IH35 WSR      ...      NaN       NaN   \n",
       "4        10th St West, 1000 blk - West of N. Lamar Blvd      NaN       NaN   \n",
       "5           10th St West, 1300 blk - West of Lorrain St      NaN       NaN   \n",
       "6             10th St West, 600 blk - West of Nueces St      NaN       NaN   \n",
       "7              10th St West, 800 blk - West of West Ave      NaN       NaN   \n",
       "8         10th St West, 900 blk - East of N. Lamar Blvd      NaN       NaN   \n",
       "9            11th St East, 1100 blk - East of Waller St      NaN       NaN   \n",
       "10         11th St East, 600 blk - East of Red River St      NaN       NaN   \n",
       "11            11th St West, 200 blk - East of Lavaca St      NaN       NaN   \n",
       "12         12th St East, 1300 blk - East of San Bernard      NaN       NaN   \n",
       "13         12th St East, 1300 blk - West of Angelina St      NaN       NaN   \n",
       "14            12th St East, 1700 blk - East of Leona St      NaN       NaN   \n",
       "15         12th St East, 400 blk - West of Red River St      NaN       NaN   \n",
       "16      12th St East, 4500 blk - West of  Springdale Rd      NaN       NaN   \n",
       "17         12th St East, 600 blk - East of Red River St      NaN       NaN   \n",
       "18       12th St West, 1000 blk - West of N. Lamar Blvd      NaN       NaN   \n",
       "19       12th St West, 1000 blk - West of N. Lamar Blvd      NaN       NaN   \n",
       "20          12th St West, 1300 blk - East of Lorrain St      NaN       NaN   \n",
       "21          12th St West, 1300 blk - East of Lorrain St      NaN       NaN   \n",
       "22          12th St West, 1400 Blk - West of Shelly Ave      NaN       NaN   \n",
       "23        13th St East, 3100 Blk - West of Airport Blvd      NaN       NaN   \n",
       "24            13th St West, 200 Blk - East of Lavaca St      NaN       NaN   \n",
       "25            13th St West, 300 Blk - West of Lavaca St      NaN       NaN   \n",
       "26      14 1/2 St East, 3100 blk - West of Airport Blvd      NaN       NaN   \n",
       "27            14th St East, 2000 Blk - West of Alamo St      NaN       NaN   \n",
       "28         15th St East, 400 blk - West of Red River St      NaN       NaN   \n",
       "29         15th St East, 600 blk - East of Red River St      NaN       NaN   \n",
       "...                                                 ...      ...       ...   \n",
       "3311    Yandall Dr, 2600 blk - West of Buster Crabbe Dr      NaN       NaN   \n",
       "3312      Yandall Dr, 2800 blk - East of Arbor Downs Rd      NaN       NaN   \n",
       "3313      Yandall Dr, 2800 blk - East of Arbor Downs Rd      NaN       NaN   \n",
       "3314         Yates Ave, 6700 blk - North of Redlands St      441     463.0   \n",
       "3315         Yates Ave, 6700 blk - North of Redlands St      393     492.0   \n",
       "3316           Yates Ave, 6800 blk - South of Justin Ln      483     459.0   \n",
       "3317          Yates Ave, 7000 blk - North of Cullen Ave      377     424.0   \n",
       "3318        Yates Ave, 7100 blk - South of Piedmont Ave      426     451.0   \n",
       "3319         Yates Ave, 7200 blk - South of Madison Ave      434     414.0   \n",
       "3320        Yates Ave, 7400 blk - South of Richcreek Rd      471     467.0   \n",
       "3321          Yaupon Dr, 6200 blk - South of Senicio Dr     1371    1410.0   \n",
       "3322          Yaupon Dr, 6200 blk - South of Senicio Dr     1426    1445.0   \n",
       "3323    Yaupon Dr, 6400 blk - South of Copper Lily Cove     1125    1120.0   \n",
       "3324     Yaupon Dr, 6700 blk - South of Bully Hill Cove     1071    1075.0   \n",
       "3325           Yaupon Dr, 7100 blk - North of Croton Dr     1084    1090.0   \n",
       "3326    Yaupon Dr, 7300 blk - North of Swan Valley Lane     1275    1276.0   \n",
       "3327    Yaupon Dr, 7300 blk - North of Swan Valley Lane     1162    1184.0   \n",
       "3328           Yaupon Dr, 7400 blk - North of Fabion Dr     1266    1288.0   \n",
       "3329             Yaupon Dr, 7600 blk - North of Fireoak     1705    1380.0   \n",
       "3330          Yaupon Dr, 7600 blk - North of Fireoak Dr     1333    1047.0   \n",
       "3331          Yaupon Dr, 7600 blk - North of Fireoak Dr      982     903.0   \n",
       "3332       Yaupon Dr, 7600 blk - South of Blue Lily Dr.     1819    1298.0   \n",
       "3333           Yaupon Dr, 7700 blk - South of Cassia Dr     1244     935.0   \n",
       "3334           Yaupon Dr, 7700 blk - South of Cassia Dr      972     911.0   \n",
       "3335  York Bridge Circle, 5700 blk - East of Manipar...      NaN       NaN   \n",
       "3336  York Bridge Circle, 6400 blk - East of Manipar...      NaN       NaN   \n",
       "3337  Zachary Scott, (@ Airport Blvd) - East of Airp...      NaN       NaN   \n",
       "3338       Zachary Scott, 2000 blk - South of Scales St      790     603.0   \n",
       "3339          Zennia, 600 blk - East of Huisache Street      NaN       NaN   \n",
       "3340  Zimmerman Ln, 11300 blk - East of RM 620, E. o...       12      12.0   \n",
       "\n",
       "      EB TOTAL   WB TOTOAL  TOTAL VOLUME                    DATE  \n",
       "0        101.0       115.0           216  09/27/2005 12:00:00 AM  \n",
       "1        103.0        55.0           158  09/27/2005 12:00:00 AM  \n",
       "2          NaN      2240.0          2240  02/26/2009 12:00:00 AM  \n",
       "3          NaN      1599.0          1599  07/06/2005 12:00:00 AM  \n",
       "4        373.0       288.0           661  01/24/2001 12:00:00 AM  \n",
       "5        383.0       314.0           697  06/05/2007 12:00:00 AM  \n",
       "6       1591.0       431.0          2022  01/11/2001 12:00:00 AM  \n",
       "7       2163.0       925.0          3088  01/30/2003 12:00:00 AM  \n",
       "8       2254.0       940.0          3194  01/30/2003 12:00:00 AM  \n",
       "9       4185.0      3788.0          7973  06/26/2006 12:00:00 AM  \n",
       "10      6544.0      5387.0         11931  03/24/2009 12:00:00 AM  \n",
       "11      3568.0      5416.0          8984  07/19/2011 12:00:00 AM  \n",
       "12      3644.0      4813.0          8457  06/23/2014 12:00:00 AM  \n",
       "13      3701.0      4395.0          8096  10/27/2009 12:00:00 AM  \n",
       "14      3393.0      4153.0          7546  10/27/2009 12:00:00 AM  \n",
       "15      1932.0      2084.0          4016  02/28/2005 12:00:00 AM  \n",
       "16      2609.0      2709.0          5318  03/22/2005 12:00:00 AM  \n",
       "17      3658.0      3074.0          6732  03/04/2009 12:00:00 AM  \n",
       "18      3335.0      2705.0          6040  02/26/2009 12:00:00 AM  \n",
       "19      4094.0      2929.0          7023  01/24/2001 12:00:00 AM  \n",
       "20      2917.0      4755.0          7672  04/28/2004 12:00:00 AM  \n",
       "21      2000.0      2181.0          4181  09/10/2001 12:00:00 AM  \n",
       "22      1881.0      2071.0          3952  09/10/2001 12:00:00 AM  \n",
       "23       171.0       321.0           492  09/13/2007 12:00:00 AM  \n",
       "24         NaN      1082.0          1082  06/08/2006 12:00:00 AM  \n",
       "25       574.0         NaN           574  06/08/2006 12:00:00 AM  \n",
       "26       218.0       332.0           550  09/13/2007 12:00:00 AM  \n",
       "27       201.0       175.0           376  02/27/2007 12:00:00 AM  \n",
       "28     15032.0      4309.0         19341  02/28/2005 12:00:00 AM  \n",
       "29     14443.0     13807.0         28250  01/31/2011 12:00:00 AM  \n",
       "...        ...         ...           ...                     ...  \n",
       "3311     433.0       355.0           788  02/26/2013 12:00:00 AM  \n",
       "3312     277.0       238.0           515  02/17/2004 12:00:00 AM  \n",
       "3313     428.0       376.0           804  02/26/2013 12:00:00 AM  \n",
       "3314       NaN         NaN           904  10/20/2003 12:00:00 AM  \n",
       "3315       NaN         NaN           885  01/28/2003 12:00:00 AM  \n",
       "3316       NaN         NaN           942  01/28/2003 12:00:00 AM  \n",
       "3317       NaN         NaN           801  06/16/2008 12:00:00 AM  \n",
       "3318       NaN         NaN           877  11/14/2007 12:00:00 AM  \n",
       "3319       NaN         NaN           848  06/16/2008 12:00:00 AM  \n",
       "3320       NaN         NaN           938  11/14/2007 12:00:00 AM  \n",
       "3321       NaN         NaN          2781  02/02/2005 12:00:00 AM  \n",
       "3322       NaN         NaN          2871  06/14/2004 12:00:00 AM  \n",
       "3323       NaN         NaN          2245  06/14/2004 12:00:00 AM  \n",
       "3324       NaN         NaN          2146  06/14/2004 12:00:00 AM  \n",
       "3325       NaN         NaN          2174  06/14/2004 12:00:00 AM  \n",
       "3326       NaN         NaN          2551  02/02/2005 12:00:00 AM  \n",
       "3327       NaN         NaN          2346  06/14/2004 12:00:00 AM  \n",
       "3328       NaN         NaN          2554  06/14/2004 12:00:00 AM  \n",
       "3329       NaN         NaN          3085  04/01/2014 12:00:00 AM  \n",
       "3330       NaN         NaN          2380  10/20/2005 12:00:00 AM  \n",
       "3331       NaN         NaN          1885  06/14/2004 12:00:00 AM  \n",
       "3332       NaN         NaN          3117  10/20/2005 12:00:00 AM  \n",
       "3333       NaN         NaN          2179  02/02/2005 12:00:00 AM  \n",
       "3334       NaN         NaN          1883  06/14/2004 12:00:00 AM  \n",
       "3335     169.0       158.0           327  04/17/2013 12:00:00 AM  \n",
       "3336     192.0       214.0           406  02/28/2013 12:00:00 AM  \n",
       "3337    1502.0      1159.0          2661  02/22/2010 12:00:00 AM  \n",
       "3338       NaN         NaN          1393  02/13/2012 12:00:00 AM  \n",
       "3339     252.0       192.0           444  09/11/2012 12:00:00 AM  \n",
       "3340       NaN         NaN            24  08/29/2005 12:00:00 AM  \n",
       "\n",
       "[3341 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1\n",
    "display(df)\n",
    "# 1. Using head, determine what the EB TOTAL is for the row with the index of 4\n",
    "\n",
    "# 2. Using tail, determine what the SB TOTAL is for the row with the index of 3331\n",
    "\n",
    "# 3. Using info, say what the data type is for NB TOTAL and EB TOTAL\n",
    "\n",
    "# 4. Using info, determine how many entries there are in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to use head/tail and info are useful tools in giving us a quick view at our data.  Now that we can see some\n",
    "values, we may want to retrieve specific values so that we can use the results in operations.  Because our axes have labels\n",
    "we can select data using the supplied labels instead of the exact indexes (as you would have to in numpy).  \n",
    "\n",
    "The mechanism that we will use, which is one of many, is the `loc` method.  You can find more documentation for this method\n",
    "[here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html#pandas.DataFrame.loc).  The basic\n",
    "syntax for a dataframe loc method is below:\n",
    "\n",
    "        df.loc[row, column]\n",
    "        \n",
    "Lets try this out by retrieving the values that we found above using the `loc` method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "\n",
    "# Using loc get the value for the EB TOTAL column with a row of index 4\n",
    "result = df.loc[_, _]\n",
    "assert result == 373.0\n",
    "\n",
    "# Using the loc get the value for the SB TOTAL column with a row of index 3331\n",
    "result = df.loc[_, _]\n",
    "assert result == 903.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `loc` method can also work with more than just a single row and single column, namely each label can be on of:\n",
    "\n",
    "- A single label (as in exercise 2)\n",
    "- A list of array of labels\n",
    "- A slice object with labels\n",
    "- A boolean array\n",
    "\n",
    "Lets try out a few of these different versions to see what information we get from each.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "\n",
    "# Using loc create a window dataframe for rows 1000 to 1005 for the columns NB TOTAL and SB TOTAL\n",
    "\n",
    "# Using loc retrieve all the rows for the column 'DATE' and display the first 5 row\n",
    "\n",
    "# Using loc retrieve the first 5 rows and the columns NB TOTAL to TOTAL VOLUME (including columns in between)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are we doing with these different patterns?  The first example is returning a dataframe that only contains\n",
    "the rows and columns that we had specified, but notice that it keeps the labels for both the rows and the columns.  \n",
    "\n",
    "The second version is actually returning a new type that we haven't talked about yet, namely a `Series` object.  We will\n",
    "discuss a series here momentarily.   \n",
    "\n",
    "The final example is also returning a dataframe, however it is using the slice operation on strings.  This is unique\n",
    "to pandas, but it understands how to work with a slice operation using the column labels, even if they are not numeric.  \n",
    "\n",
    "**NOTE:** It is important to call out that slices in pandas do not work the same as python, where python slices are none\n",
    "inclusive on the upper bound, pandas slices are inclusive.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "So in our last exercise we came across a new type from pandas, the `Series`.  A series in pandas is an objec that represents\n",
    "a one-dimensional structure, much like a list.  Anytime you work with a 1D object it will be in the form of a series, \n",
    "while anytime you work with something that is 2D it will be a dataframe.  \n",
    "\n",
    "In essence, you can consider that a dataframe is a collection of columns, where each column is a series.  _This is actually\n",
    "how it is stored internally_.  \n",
    "\n",
    "When requesting the data, if you select a single row or select a single column you will end up with a series.  It is very important\n",
    "to note that series will maintain their labels whenever possible.  \n",
    "\n",
    "Once you have access to a series, like a dataframe you can use the `loc` to retrieve an exact value, but unlike a dataframe the series\n",
    "loc only accepts one dimension.  \n",
    "\n",
    "        series.loc[label]\n",
    "        \n",
    "**NOTE:** Pandas heavy utilizes the notion of method chaining.  This is done so that operations can be run without the\n",
    "need to intermediate temporary variables.  This means that you can run a `loc` from a series on the results of a `loc`\n",
    "from a dataframe.  \n",
    "\n",
    "        df.loc[:, 'NB TOTAL'].loc[3]\n",
    "\n",
    "Besides just retrieving specific value from a series, there are some other useful functions that we can work with.  \n",
    "\n",
    "- `describe()` - descriptive statiscs on data in a series\n",
    "- `max()`\n",
    "- `min()`\n",
    "- `mean()`\n",
    "- `median()`\n",
    "- `mode()`\n",
    "- `sum()`\n",
    "- `value_counts()`\n",
    "\n",
    "These methods are useful in giving us some basic insight into the data that we have available to us.  Let's try some of these\n",
    "methods out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4\n",
    "\n",
    "# 1. First lets describe the data for the 'SB TOTAL' column\n",
    "\n",
    "# 2. Lets use describe on the data for the `NB TOTAL` column\n",
    "\n",
    "# 3. Get the max for the 'EB TOTAL' column and assign it to eb_total_max\n",
    "\n",
    "#assert eb_total_max == 30033.0\n",
    "\n",
    "# 4. Display the top 10 unique values for the `DATE` column\n",
    "\n",
    "# 5. Get the median for the column `NB TOTAL`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, the 5th part of the above exercise should have given you an error.  Namely an error about converting a string\n",
    "to a number (the string being `no count`).  It seems like we have some bad data in our `NB TOTAL` column.  At this point, using only the\n",
    "tools above, we would need to scan through our table to find the bad columns.  \n",
    "\n",
    "Luckily, pandas dataframe offer more than just an easy way to view our data.  This power is part of the querying capabilities.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying\n",
    "\n",
    "We haven't yet talked much about it, but pandas provides the ability to retrieve rows and columns from a sequence of booleans.  \n",
    "\n",
    "        df.loc[[True, False, False, True, False, True], 'NB TOTAL':'TOTAL VOLUME']\n",
    "        \n",
    "This allows us to create conditions for when a row or column should be returned.  What's even more powerful is the fact that\n",
    "the series object in pandas has over loaded some operators to allow a series to generate a boolean series given specific\n",
    "conditions.  For example the below command will return a boolean series where the `TOTAL VOLUME` is more than 1000.  \n",
    "\n",
    "        df.loc[:, 'TOTAL VOLUME'] > 1000\n",
    "        \n",
    "Besides the common overload operators, pandas provides methods that we can use to create boolean series based on a\n",
    "given criteria, for example the below command will return all the rows where the value for the `SB TOTAL` column is not `NaN`.  \n",
    "\n",
    "        pd.notna(df.loc[:, 'SB TOTAL'])\n",
    "        \n",
    "Other useful commands that pandas provides for querying information include.  \n",
    "\n",
    "- `pandas.isna()`\n",
    "- `pandas.isnull()`\n",
    "- `pandas.notnull()`\n",
    "\n",
    "Finally, you can combine multiple conditional queries using the `&` operator (or uses the `|` operator).  So a command\n",
    "that will retrieve rows where the `SB TOTAL` is greater than 10000 but the `TOTAL VOLUME` is less than 20000 would look like\n",
    "this.  \n",
    "\n",
    "        df.loc[(df.loc[:, 'SB TOTAL'] > 10000) & (df.loc[:, 'TOTAL VOLUME'] < 20000)].head(5)\n",
    "\n",
    "Let's start with a couple of exercises to test our knowledge of using these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5\n",
    "\n",
    "# 1. Display the first 5 rows where the TOTAL VOLUME is greater than 10000\n",
    "\n",
    "# 2. Display the first 5 rows where the NB TOTAL is not null\n",
    "\n",
    "# 3. Display the rows where there is a value in both `SB TOTAL` and in `EB TOTAL`\n",
    "\n",
    "# 4. Display the sum of 'EB TOTAL' for the rows where the `EB TOTAL` is an even number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until this point we have only referenced columns using the `loc` method.  Pandas does provide a few other\n",
    "formats that you can use.  Each of these below commands will all return the same value.  \n",
    "\n",
    "    df.low[:, 'DATE']\n",
    "    df['DATE']\n",
    "    df.DATE\n",
    "    \n",
    "There are also other commands that you can use besides `loc`.  \n",
    "\n",
    "    df.loc[0, 'NB TOTAL']\n",
    "    df.iloc[0, 1]\n",
    "    df.at[0, 'NB TOTAL']\n",
    "    df.iat[0, 1]\n",
    "    \n",
    "This means that the above commands could have been re-written, for example the answer for number 4 could have been written\n",
    "as:\n",
    "\n",
    "    df[df['EB TOTAL'] % 2 == 0]['EB TOTAL']\n",
    "    # or\n",
    "    df.loc[df['EB TOTAL'] % 2 == 0, 'EB TOTAL']\n",
    "    \n",
    "**NOTE:** The difference between `at` and `loc`, is that while `loc` can return a series or dataframe, `at` will only\n",
    "return a scalar, this means it does not support slicing.  \n",
    "\n",
    "**2nd NOTE:** While the different column and loc methods will return the same results, they are not the same operation\n",
    "and this has to do with pandas returning a `view` or a `copy` of the data.  But for simple quering purposes they will work the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframes also have some other useful methods for querying data values or returnings a different dataframe\n",
    "to work with.  These include the following commands.  \n",
    "\n",
    "- nsmallest(n, columns) - `df.nsmallest(5, columns='TOTAL VOLUME')`\n",
    "- nlargest(n, columns) - `df.nlargest(5, columns=['TOTAL VOLUME', 'EB TOTAL'])`\n",
    "- sample(n) - A random sample of `n` instances (rows) from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6\n",
    "\n",
    "# 1. What is the sum of the `TOTAL VOLUME` for the 2 largest in `EB TOTAL`.  \n",
    "#   Should come up with 117,269\n",
    "\n",
    "# 2. What is the sum of the `TOTAL VOLUME` for the 3 smallest `SB TOTAL` values\n",
    "#   Should come up with 132\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "Some of you may have noticied or wondered (or possibly even asked a question) about why we aren't using `NB TOTAL`.  If\n",
    "you recall from the very beginning, this column was of type `object` and not a numeric type, which means we can't use\n",
    "or aggregate functions against that column until we fix the data.  \n",
    "\n",
    "For this next section we are going to go through our data in an attempt to either remove or adjust results where\n",
    "appropriate.  \n",
    "\n",
    "Now there are a lot of things that we can do to our data to clean it up.  The first thing that I want to do is adjust\n",
    "the names of the colums that we are using so that I can use `nb` instead of `NB TOTAL` for all of my commands.  Pandas\n",
    "provides a few ways for us to do this, either by assigning the new names to the `columns` property of the dataframe\n",
    "or by using the `rename` method.  \n",
    "\n",
    "In this next exercise, rename the columns in our dataframe according to the map below.  \n",
    "\n",
    "- `24 HOUR VOLUME COUNT LOCATIONS` -> `location`\n",
    "- `NB TOTAL` -> `nb`\n",
    "- `SB TOTAL` -> `sb`\n",
    "- `EB TOTAL` -> `eb\n",
    "- ` WB TOTOAL` -> `wb`\n",
    "- `TOTAL VOLUME` -> `total`\n",
    "- `DATE` -> `date`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7\n",
    "\n",
    "# 1. Rename all the columns according to the list above\n",
    "\n",
    "# 2. Select the first 5 instances where the `sb` value is less than 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our next cleanup task is going to be a little more involved, first we need to find all the \n",
    "data in the `nb` column that is a non-numeric, the columns that are stopping us from using our\n",
    "aggregate functions.  \n",
    "\n",
    "If we were using standard python I could compare the value to see if it can be cast to number\n",
    "or not.  Since this is a common operation, pandas provides this ability for us, but using\n",
    "the `str` property of a series, it will give us the functions provided by pandas for string\n",
    "types, one of which is the `isnumeric()` function.  There are a few others, some of which\n",
    "are listed here.  \n",
    "\n",
    "- `str.contains()`\n",
    "- `str.endswith()`\n",
    "- `str.len()`\n",
    "- `str.isdigit()`\n",
    "- `str.isalpha()`\n",
    "- `str.isspace()`\n",
    "\n",
    "Using the above commands is done as demonstrated below.  \n",
    "\n",
    "    df['location'].str.contains('Barton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8\n",
    "\n",
    "# 1. Create a variable `na_rows` that contains a boolean series where nb is NaN\n",
    "na_rows = pd.isna(df['nb'])\n",
    "\n",
    "# 1. Create a variable `good_rows` that contains a boolean series where nb is NaN or numeric\n",
    "number_rows =  (na_rows | df['nb'].str.isnumeric())\n",
    "\n",
    "# 3. Display the rows where nb is not numeric or NaN (note you can use ~ to negate a boolean series)\n",
    "df[~number_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have our bad rows, and it looks like we have the following errors.  \n",
    "\n",
    "- 2 rows `during rd. construction`\n",
    "- 3 rows `no count`\n",
    "\n",
    "At this point we have a decision to make.  This data will obviously not work as we need our `nb` column\n",
    "to contain numeric data, so we can do one of the following.  \n",
    "\n",
    "1. Set the bad values to `NaN`\n",
    "2. Set the bad values to 0\n",
    "3. Set the bad values to the mean of the column\n",
    "4. Drop the rows with the bad values\n",
    "\n",
    "Which option we choose will larger depend upon whether we need the other information provided and if we\n",
    "feel that using any of those options could drastically skew our perception of the data.  For this exercise\n",
    "we are going to simply drop these rows.  This can be done by using the `drop` function.  \n",
    "\n",
    "    df.drop(index=[row1, row2, row10])\n",
    "    \n",
    "Lets go ahead and run the drop command and then describe the dataframe and output the last 5 results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9\n",
    "\n",
    "# 1. Get the indexes of the rows to drop using the number_rows column above (remember to negate it) store in variable drop_rows\n",
    "\n",
    "# 1. Run the drop command on the rows from the inverted boolean variable number_rows, save the results in dropped_df\n",
    "\n",
    "# 2. Display the describe output for the dropped_df dataframe for column nb\n",
    "\n",
    "# 3. Display the rows 470 to 478\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our last cleanup step, lets now fix a couple of our types.  Right now we have dropped the columns from `nb`\n",
    "that were causing it to not automatically be discovered as a number so we can now convert that column.  But\n",
    "the other column that is also an incorrect type is the `date` column which is currently of type `object` but\n",
    "can be of type `datetime`.  \n",
    "\n",
    "To convert an entire series, you can use the provided pandas methods:\n",
    "\n",
    "- `pandas.to_numeric(series)`\n",
    "- `pandas.to_datetime(series)`\n",
    "\n",
    "If we want to update a column, we can do so by selecting the column using the `loc` on a dataframe.  After selecting\n",
    "you need to supply a scalar (single value) or a series or sequence with the same number of instances (rows) as the\n",
    "dataframe.  This is done simply by specifying the column to overwrite and the values to apply.  \n",
    "\n",
    "    df['nb'] = new_values\n",
    "\n",
    "For this next exercise lets create a converted series that is of the correct types.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 10\n",
    "\n",
    "# 1. Create a new series that is the nb series converted to numeric, store in number_nb\n",
    "\n",
    "# 2. Create a new series that is the date series converted to a datetime, store in datetime_date\n",
    "\n",
    "# 3. Assign the updated series to both the nb and date columns\n",
    "\n",
    "# 4. Display the dtypes of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have now cleaned up our datatypes, but we still have one thing that could cause us some problems, namely we\n",
    "have `NaN` in a lot of places that if we try to run our own calculations against are going to cause issues.  So what\n",
    "we want to do is to convert all the `NaN` values to 0.  In doing this we are, however, possibly lossing some information,\n",
    "namely which direction a road is traveling.  \n",
    "\n",
    "Looking over the data it seems that a road is considered traveling north to south when there is a value in either the\n",
    "`nb` or the `sb` columns.  The same thing goes for `eb` and `wb`.  So what we want to do is create two more columns\n",
    "on our dataframe.  These columns are going to be boolean columns and contain True when the direction traveled is either\n",
    "`nb` or `sb` and `eb` or `wb`.  \n",
    "\n",
    "Finally pandas provides a helper function that will automatically fill in all entries in a dataframe with a supplied value\n",
    "when the original value in the cell is `NaN`, this command is `fillna()` on the dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 11\n",
    "\n",
    "# 1. Create a boolean series named ns_traffic that is true when either nb or sb is not NaN\n",
    "\n",
    "# 2. Create a boolean series named ew_traffic that is true when either wb or eb is not NaN\n",
    "\n",
    "# 3. Create a new column on the dataframe named `ns` and assign the ns_traffic series\n",
    "\n",
    "# 4. Create a new column on the dataframe named `ew` and assign the ew_traffic series\n",
    "\n",
    "# 5. Using the fillna function to set all the NaN values to 0 and save the results in zero_df\n",
    "\n",
    "# 6. Display the first 5 rows of the zero_df dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "At this point we now have a dataframe that has been cleaned and would be ready for further inspection\n",
    "or even possible use in a machine learning model.  (__Further vectorization likely\n",
    "required__).  \n",
    "\n",
    "To make sure that we persist our changes we can store our results back to the filesystem in csv\n",
    "format to be loaded later.  This is done in the following cell.  \n",
    "\n",
    "For our next notebook lets look at the visual capabilities that are provided by pandas, especially\n",
    "when used with timeseries data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_name = os.path.join('..', '.data', 'austin_cleaned.csv')\n",
    "zero_df.to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
