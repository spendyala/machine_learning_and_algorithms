{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    "Now that we have learned about optimizing code.\n",
    "Let's implement a machine learning algorithm called `K-Nearest Neighbor` or knn.\n",
    "\n",
    "\n",
    "In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression.[1] In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:\n",
    "\n",
    " * In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n",
    "\n",
    " * In k-NN regression, the output is the property value for the object. This value is the average of the values of its k nearest neighbors.\n",
    "\n",
    "First let's go over a simple implementation of KNN in strict Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ../.data\n",
    "cd ../.data\n",
    "if [ ! -f iris.data.txt ]; then\n",
    "    echo \"File not found. Downloading from github\"\n",
    "    wget -q https://raw.githubusercontent.com/WinVector/Logistic/master/iris.data.txt\n",
    "else\n",
    "    echo \"File exists, not downloading form github\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def read_iris_data():\n",
    "    data = pd.read_csv('../.data/iris.data.txt').values\n",
    "    np.random.shuffle(data)\n",
    "    return data[:,0:4], data[:,4]\n",
    "\n",
    "X, Y = read_iris_data()\n",
    "X = X.astype('float64')\n",
    "x_train = X[:120]\n",
    "y_train = Y[:120]\n",
    "x_test = X[120:]\n",
    "y_test = Y[120:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running our Model\n",
    "Below is a simple runner class. It will simply train the model and call model predict to get classifier accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        model.train(x_train, y_train)\n",
    "\n",
    "    def test(self):\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        for x, y in zip(x_test, y_test):\n",
    "            if self.model.predict(x) == y:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "        return correct, incorrect\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Python\n",
    "First let's walk through KNN in strict Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from heapq import nsmallest\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.train_data = None\n",
    "        self.labels = None\n",
    "\n",
    "\n",
    "    def train(self, train_data, labels):\n",
    "        self.train_data = list(train_data)\n",
    "        self.labels = labels\n",
    "    \n",
    "    def _get_distance_squared(self, point):\n",
    "        '''\n",
    "        euclidean distance = sqrt(x^2+y^2...)\n",
    "        not taking the square root will speed up the code and will not change the ordering of what points are closest to our point\n",
    "        '''\n",
    "        distances = [0.] * len(self.train_data)\n",
    "        for i, row in enumerate(self.train_data):\n",
    "            for r_n, p_n in zip(row, point):\n",
    "                distances[i] += abs(p_n-r_n)\n",
    "        return distances\n",
    "    \n",
    "    def predict(self, data):\n",
    "        distances = self._get_distance_squared(data)\n",
    "        distance_labels = list(zip(distances, self.labels))\n",
    "        distance_labels.sort(key=lambda x: x[0])\n",
    "        k_nearest = [x[1] for x in distance_labels[:self.k]]\n",
    "        most_common = Counter(k_nearest).most_common(1)[0][0]\n",
    "        return most_common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN()\n",
    "runner = Runner(knn)\n",
    "correct, incorrect = runner.test()\n",
    "print(correct, incorrect)\n",
    "%timeit runner.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "\n",
    "Now let's briefly go over the same code implemented in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from heapq import nsmallest\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class KNN_np:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.train_data = None\n",
    "        self.labels = None\n",
    "\n",
    "\n",
    "    def train(self, train_data, labels):\n",
    "        self.train_data = train_data\n",
    "        self.labels = labels\n",
    "\n",
    "    \n",
    "    def _get_distances(self, data):\n",
    "        distances = data - self.train_data\n",
    "        absolute_distances = distances**2\n",
    "        return np.sum(absolute_distances, axis=1)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        distances = self._get_distances(data)\n",
    "        \n",
    "        partition = np.argpartition(distances, 5)\n",
    "        kclosest = self.labels[partition[0 : self.k]]\n",
    "        return Counter(kclosest).most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN_np()\n",
    "runner = Runner(knn)\n",
    "correct, incorrect = runner.test()\n",
    "print(correct, incorrect)\n",
    "%timeit runner.test()\n",
    "%timeit runner.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba\n",
    "\n",
    "See if you can implement KNN using Numba + NumPy\n",
    "Or you can review my code and try to optimize it. I left a lot of code to be optimized.\n",
    "\n",
    "> Numba is still a beta so I ran into an exception durring the jit compile.\n",
    "Enumerating over a 2d ndarray hasn't been implemented yet.\n",
    "So in code comments I left the fix (a 2 line refactor refactor from enumerate to range).\n",
    "But it is still a 0.x release so give Numba some credit. They have done a lot for a JIT compiler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from heapq import nsmallest\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "@njit\n",
    "def sum(x):\n",
    "    s = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        s += x[i]\n",
    "    return s\n",
    "\n",
    "@njit\n",
    "def get_distances(x, train_data):\n",
    "    distances = np.zeros(train_data.shape[0], dtype=np.float64)\n",
    "#     for i, row in enumerate(train_data):\n",
    "#         This throws a not implemented exception. The bugfix is below\n",
    "    for i in range(train_data.shape[0]):\n",
    "        row = train_data[i]\n",
    "        s = 0\n",
    "        for j in range(row.shape[0]):\n",
    "            s += (x[j] - row[j])**2\n",
    "        distances[i] = s\n",
    "    return distances\n",
    "\n",
    "\n",
    "class KNN_Numba:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.train_data = None\n",
    "        self.labels = None\n",
    "\n",
    "\n",
    "    def train(self, train_data, labels):\n",
    "        self.train_data = train_data\n",
    "        self.labels = labels\n",
    "        self.max_values = np.amax(np.absolute(self.train_data), axis=0)\n",
    "\n",
    "\n",
    "    def predict(self, data):\n",
    "        distances = get_distances(data, self.train_data)\n",
    "        \n",
    "        partition = np.argpartition(distances, 5)\n",
    "        kclosest = self.labels[partition[0 : self.k]]\n",
    "        return Counter(kclosest).most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from heapq import nsmallest\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "class KNN_Numba:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.train_data = None\n",
    "        self.labels = None\n",
    "\n",
    "    def train(self, train_data, labels):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, data):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN_Numba()\n",
    "runner = Runner(knn)\n",
    "correct, incorrect = runner.test()\n",
    "print(correct, incorrect)\n",
    "%timeit runner.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython\n",
    "\n",
    "Try to implement this in Cython.\n",
    "In my implementation I was able to get speeds much faster than Numpy.\n",
    "\n",
    "Numpy is really fast, but Cython can be faster when you know exactly what you want.\n",
    "\n",
    "Give it a shot and see if you can beat Numpy speeds on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "import cython\n",
    "cimport cython\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cdef struct Score:\n",
    "    int index\n",
    "    float distance\n",
    "\n",
    "ctypedef double[:,:] Matrix\n",
    "ctypedef double[:] Vector\n",
    "\n",
    "cdef float get_distance(int vector_length, Vector vector1, Vector vector2):\n",
    "    cdef float distance, total_distance\n",
    "    cdef int i\n",
    "    total_distance = 0.0\n",
    "    for i in range(vector_length):\n",
    "        distance = vector1[i] - vector2[i]\n",
    "        if distance < 0:\n",
    "            distance *= -1\n",
    "        total_distance += distance\n",
    "    return total_distance\n",
    "\n",
    "cdef class KNNC:\n",
    "\n",
    "    cdef int _k, _vector_length, _training_instances\n",
    "    cdef Matrix _train_data\n",
    "    cdef object labels\n",
    "\n",
    "    def __init__(self, int k):\n",
    "        self._k = k\n",
    "        self._vector_length = 0\n",
    "        self._training_instances = 0\n",
    "\n",
    "    def train(self, Matrix train_data, labels):\n",
    "        # self._train_data = train_data\n",
    "        self.labels = labels\n",
    "        self._vector_length = len(train_data[0])\n",
    "        self._training_instances = len(train_data)\n",
    "        self._train_data = train_data\n",
    "\n",
    "\n",
    "    @cython.nonecheck(False)\n",
    "    def predict(self, Vector data):\n",
    "        cdef Score[50] closest\n",
    "        cdef int i, j, tmp_index\n",
    "        cdef float distance, tmp_distance\n",
    "        cdef Vector compared\n",
    "\n",
    "        for i in range(self._k):\n",
    "            closest[i] = Score(index=0, distance=100000.)\n",
    "        for i in range(self._training_instances):\n",
    "            compared = self._train_data[i]\n",
    "            distance = get_distance(self._vector_length, data, compared)\n",
    "            for j in range(self._k):\n",
    "                if distance < closest[j].distance:\n",
    "                    tmp_distance = closest[j].distance\n",
    "                    tmp_index = closest[j].index\n",
    "                    closest[j].distance = distance\n",
    "                    closest[j].index = i\n",
    "                    i = tmp_index\n",
    "                    distance = tmp_distance\n",
    "        closest_classes = Counter([self.labels[x.index] for x in closest[:self._k]])\n",
    "        return closest_classes.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "\n",
    "cdef class KNNC:\n",
    "    cdef int k\n",
    "    cdef np.ndarray train_data\n",
    "\n",
    "\n",
    "    def __init__(self, int k):\n",
    "        self.k = k\n",
    "        \n",
    "    def train(self, np.ndarray train_data, np.ndarray labels):\n",
    "        pass\n",
    "\n",
    "    def predict(self, Vector data):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNC(5)\n",
    "runner = Runner(knn)\n",
    "correct, incorrect = runner.test()\n",
    "print(correct, incorrect)\n",
    "%timeit runner.test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "Tensorflow is the tool to write machine learning algorithms.\n",
    "It is designed to run very complex algorithms very quickly with some startup overhead to set up `tensors`\n",
    "\n",
    "My implementation is definitely not the most efficient algorithm.\n",
    "But if you are interested in learning tensorflow, knn is a very simple algorithm to help you learn the most common neural net framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class KNNtf:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "\n",
    "    def train(self, train_data, labels):\n",
    "        instance_shape = train_data[0].shape\n",
    "        self.labels = labels\n",
    "        knn_graph = tf.Graph()\n",
    "        with knn_graph.as_default():\n",
    "            # set up variables\n",
    "            train_features = tf.constant(train_data)\n",
    "            X = tf.placeholder(shape=instance_shape, dtype=train_data.dtype, name='X')\n",
    "            Y = tf.placeholder(shape=(1,), dtype=np.float32, name='X')\n",
    "            tf_labels = tf.constant(labels)\n",
    "\n",
    "            # get distance\n",
    "            difference = tf.abs(train_features - X)\n",
    "            distance = tf.reduce_sum(difference, 1)\n",
    "\n",
    "            # find the k nearest neighbors\n",
    "            k_nearest_neighbors_indices = tf.nn.top_k(-distance, k=self.k).indices\n",
    "            k_nearest_neighbors = tf.gather(tf_labels, k_nearest_neighbors_indices)\n",
    "\n",
    "            # get the class of the most common class in k nearest neighbors\n",
    "            y, idx, count = tf.unique_with_counts(k_nearest_neighbors)\n",
    "            max_index = tf.argmax(count)\n",
    "            nearest_neighbor = tf.gather(y, max_index)\n",
    "\n",
    "            sess = tf.Session()\n",
    "        # set a function to call to get the prediction\n",
    "        self._model = lambda features: sess.run(nearest_neighbor, feed_dict={'X:0': features})\n",
    "\n",
    "    def predict(self, data):\n",
    "        nn = tf.compat.as_text(self._model(data))\n",
    "        return nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNtf()\n",
    "runner = Runner(knn)\n",
    "correct, incorrect = runner.test()\n",
    "print(correct, incorrect)\n",
    "%timeit runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
